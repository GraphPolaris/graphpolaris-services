{
  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "clusterName": {
      "type": "string",
      "defaultValue": "[concat('aks-cluster-', uniqueString(resourceGroup().id))]",
      "metadata": {
        "description": "Name of the AKS cluster"
      }
    },
    "location": {
      "type": "string",
      "defaultValue": "[resourceGroup().location]",
      "metadata": {
        "description": "Location for all resources"
      }
    },
    "nodeCount": {
      "type": "int",
      "defaultValue": 3,
      "minValue": 3,
      "maxValue": 10,
      "metadata": {
        "description": "Number of nodes in the agent pool"
      }
    },
    "nodeVmSize": {
      "type": "string",
      "defaultValue": "Standard_B2s",
      "metadata": {
        "description": "Size of the VMs in the agent pool"
      }
    },
    "kubernetesVersion": {
      "type": "string",
      "defaultValue": "1.31",
      "metadata": {
        "description": "Kubernetes version"
      }
    },
    "dnsPrefix": {
      "type": "string",
      "defaultValue": "[concat('aks-', uniqueString(resourceGroup().id))]",
      "metadata": {
        "description": "DNS prefix for the AKS cluster"
      }
    },
    "servicePrincipalClientId": {
      "type": "string",
      "defaultValue": "",
      "metadata": {
        "description": "Service principal client ID (appId). If not provided, a managed identity will be used."
      }
    },
    "servicePrincipalClientSecret": {
      "type": "securestring",
      "defaultValue": "",
      "metadata": {
        "description": "Service principal client secret. Required if servicePrincipalClientId is provided."
      }
    },
    "helmRegistry": {
      "type": "string",
      "metadata": {
        "description": "Helm OCI registry URL"
      }
    },
    "helmRegistryUser": {
      "type": "string",
      "metadata": {
        "description": "Helm registry username"
      }
    },
    "helmRegistryPassword": {
      "type": "securestring",
      "metadata": {
        "description": "Helm registry password"
      }
    },
    "helmChartName": {
      "type": "string",
      "metadata": {
        "description": "Name of the Helm chart to install"
      }
    },
    "helmChartVersion": {
      "type": "string",
      "metadata": {
        "description": "Version of the Helm chart to install"
      }
    },
    "dockerConfigJson": {
      "type": "securestring",
      "metadata": {
        "description": "Base64 encoded docker config JSON for registry credentials"
      }
    },
    "admin_user": {
      "type": "string",
      "metadata": {
        "description": "Admin user for clientGateway service"
      }
    },
    "admin_password": {
      "type": "securestring",
      "metadata": {
        "description": "Admin password for clientGateway service"
      }
    }
  },
  "variables": {
    "useManagedIdentity": "[empty(parameters('servicePrincipalClientId'))]"
  },
  "resources": [
    {
      "type": "Microsoft.ContainerService/managedClusters",
      "apiVersion": "2023-11-01",
      "name": "[parameters('clusterName')]",
      "location": "[parameters('location')]",
      "identity": "[if(variables('useManagedIdentity'), createObject('type', 'SystemAssigned'), json('null'))]",
      "properties": {
        "kubernetesVersion": "[parameters('kubernetesVersion')]",
        "dnsPrefix": "[parameters('dnsPrefix')]",
        "agentPoolProfiles": [
          {
            "name": "agentpool",
            "count": "[parameters('nodeCount')]",
            "vmSize": "[parameters('nodeVmSize')]",
            "osType": "Linux",
            "mode": "System",
            "type": "VirtualMachineScaleSets",
            "enableAutoScaling": false
          }
        ],
        "servicePrincipalProfile": "[if(variables('useManagedIdentity'), json('null'), createObject('clientId', parameters('servicePrincipalClientId'), 'secret', parameters('servicePrincipalClientSecret')))]",
        "networkProfile": {
          "networkPlugin": "kubenet",
          "loadBalancerSku": "Standard",
          "loadBalancerProfile": {
            "managedOutboundIPs": {
              "count": 1
            }
          }
        },
        "addonProfiles": {
          "httpApplicationRouting": {
            "enabled": false
          }
        },
        "enableRBAC": true
      }
    },
    {
      "type": "Microsoft.Resources/deploymentScripts",
      "apiVersion": "2023-08-01",
      "name": "[concat('deploy-graphpolaris-services-', uniqueString(resourceGroup().id))]",
      "location": "[parameters('location')]",
      "kind": "AzureCLI",
      "dependsOn": [
        "[resourceId('Microsoft.ContainerService/managedClusters', parameters('clusterName'))]"
      ],
      "identity": {
        "type": "UserAssigned",
        "userAssignedIdentities": {
          "[resourceId('Microsoft.ManagedIdentity/userAssignedIdentities', concat('id-', uniqueString(resourceGroup().id)))]": {}
        }
      },
      "properties": {
        "azCliVersion": "2.50.0",
        "timeout": "PT30M",
        "retentionInterval": "P1D",
        "environmentVariables": [
          {
            "name": "CLUSTER_NAME",
            "value": "[parameters('clusterName')]"
          },
          {
            "name": "RESOURCE_GROUP",
            "value": "[resourceGroup().name]"
          },
          {
            "name": "SUBSCRIPTION_ID",
            "value": "[subscription().subscriptionId]"
          },
          {
            "name": "HELM_REGISTRY",
            "value": "[parameters('helmRegistry')]"
          },
          {
            "name": "HELM_REGISTRY_USER",
            "value": "[parameters('helmRegistryUser')]"
          },
          {
            "name": "HELM_REGISTRY_PASSWORD",
            "value": "[parameters('helmRegistryPassword')]"
          },
          {
            "name": "HELM_CHART_NAME",
            "value": "[parameters('helmChartName')]"
          },
          {
            "name": "HELM_CHART_VERSION",
            "value": "[parameters('helmChartVersion')]"
          },
          {
            "name": "DOCKER_CONFIG_JSON",
            "value": "[parameters('dockerConfigJson')]"
          },
          {
            "name": "ADMIN_USER",
            "value": "[parameters('admin_user')]"
          },
          {
            "name": "ADMIN_PASSWORD",
            "value": "[parameters('admin_password')]"
          }
        ],
        "scriptContent": "#!/bin/bash\nset -e\n\n# Set the subscription explicitly (managed identity is already authenticated)\naz account set --subscription $SUBSCRIPTION_ID\n\n# Verify subscription\naz account show --output table\n\n# Install kubectl if not available\nif ! command -v kubectl &> /dev/null; then\n  echo \"Installing kubectl...\"\n  # Try az aks install-cli first, fallback to direct download\n  if ! az aks install-cli 2>/dev/null; then\n    KUBECTL_VERSION=$(curl -L -s https://dl.k8s.io/release/stable.txt)\n    curl -LO \"https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl\"\n    chmod +x kubectl\n    sudo mv kubectl /usr/local/bin/kubectl || mv kubectl /usr/local/bin/kubectl\n  fi\n  kubectl version --client\nfi\n\n# Install Helm if not available\nif ! command -v helm &> /dev/null; then\n  echo \"Installing Helm...\"\n  curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n  helm version\nfi\n\n# Install jq if not available\nif ! command -v jq &> /dev/null; then\n  echo \"Installing jq...\"\n  sudo apt-get update && sudo apt-get install -y jq || \\\n  (curl -L https://github.com/jqlang/jq/releases/download/jq-1.7.1/jq-linux-amd64 -o /tmp/jq && chmod +x /tmp/jq && sudo mv /tmp/jq /usr/local/bin/jq)\n  jq --version\nfi\n\n# Get AKS credentials using admin (simpler, doesn't require cluster user role)\naz aks get-credentials --resource-group $RESOURCE_GROUP --name $CLUSTER_NAME --admin --overwrite-existing\n\n# Wait for nodes to be ready\nkubectl wait --for=condition=Ready nodes --all --timeout=300s || true\n\n# Enable OCI support for Helm\nexport HELM_EXPERIMENTAL_OCI=1\n\n# Login to Helm registry\necho \"Logging in to Helm registry $HELM_REGISTRY...\"\necho \"$HELM_REGISTRY_PASSWORD\" | helm registry login -u \"$HELM_REGISTRY_USER\" --password-stdin \"https://$HELM_REGISTRY\"\n\n# Install graphpolaris-services Helm chart\necho \"Installing $HELM_CHART_NAME chart version $HELM_CHART_VERSION...\"\n\n# Create values file with dockerconfigjson and admin credentials for clientGateway and databaseService\necho \"Creating Helm values file...\"\nif [ -z \"$DOCKER_CONFIG_JSON\" ]; then\n  echo \"WARNING: DOCKER_CONFIG_JSON is empty. Image pulls may fail!\"\nfi\ncat > /tmp/helm-values.yaml <<EOF\nglobal:\n  registryCredentials:\n    dockerconfigjson: \"$DOCKER_CONFIG_JSON\"\nclientGateway:\n  env:\n    ADMIN_USER: \"$ADMIN_USER\"\n    ADMIN_PASSWORD: \"$ADMIN_PASSWORD\"\ndatabaseService:\n  env:\n    ADMIN_USER: \"$ADMIN_USER\"\n    ADMIN_PASSWORD: \"$ADMIN_PASSWORD\"\nEOF\n\necho \"Helm values file created:\"\ncat /tmp/helm-values.yaml | sed 's/dockerconfigjson:.*/dockerconfigjson: [REDACTED]/' | sed 's/ADMIN_PASSWORD:.*/ADMIN_PASSWORD: [REDACTED]/'\n\nhelm upgrade --install graphpolaris-services \\\n  \"oci://$HELM_REGISTRY/graphpolaris-helm/$HELM_CHART_NAME\" \\\n  --version \"$HELM_CHART_VERSION\" \\\n  -f /tmp/helm-values.yaml \\\n  --wait --timeout 15m\n\n# Wait for all deployments to be ready\necho \"Waiting for all deployments to be ready...\"\nkubectl wait --for=condition=available --timeout=600s deployment --all --all-namespaces || true\n\n# Get all LoadBalancer service IPs\necho \"\\n=== LoadBalancer Service IPs ===\"\nLOADBALANCER_SERVICES=$(kubectl get svc --all-namespaces -o json | jq -r '.items[] | select(.spec.type==\"LoadBalancer\") | \"\\(.metadata.namespace)/\\(.metadata.name)\"')\n\nif [ -z \"$LOADBALANCER_SERVICES\" ]; then\n  echo \"No LoadBalancer services found yet. Waiting...\"\n  sleep 30\n  LOADBALANCER_SERVICES=$(kubectl get svc --all-namespaces -o json | jq -r '.items[] | select(.spec.type==\"LoadBalancer\") | \"\\(.metadata.namespace)/\\(.metadata.name)\"')\nfi\n\n# Wait for LoadBalancer IPs to be assigned\nRETRY=0\nMAX_RETRIES=30\n\nwhile [ $RETRY -lt $MAX_RETRIES ]; do\n  ALL_IPS_ASSIGNED=true\n  \n  echo \"\\nChecking LoadBalancer IPs (attempt $((RETRY + 1))/$MAX_RETRIES)...\"\n  \n  for service in $LOADBALANCER_SERVICES; do\n    NAMESPACE=$(echo $service | cut -d'/' -f1)\n    SERVICE_NAME=$(echo $service | cut -d'/' -f2)\n    IP=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo \"\")\n    \n    if [ -z \"$IP\" ]; then\n      ALL_IPS_ASSIGNED=false\n      echo \"  $NAMESPACE/$SERVICE_NAME: Pending...\"\n    else\n      echo \"  $NAMESPACE/$SERVICE_NAME: $IP\"\n    fi\n  done\n  \n  if [ \"$ALL_IPS_ASSIGNED\" = true ] && [ -n \"$LOADBALANCER_SERVICES\" ]; then\n    break\n  fi\n  \n  RETRY=$((RETRY + 1))\n  if [ $RETRY -lt $MAX_RETRIES ]; then\n    sleep 10\n  fi\n  \n  # Refresh service list\n  LOADBALANCER_SERVICES=$(kubectl get svc --all-namespaces -o json | jq -r '.items[] | select(.spec.type==\"LoadBalancer\") | \"\\(.metadata.namespace)/\\(.metadata.name)\"')\ndone\n\n# Output final LoadBalancer IPs\necho \"\\n=== Final LoadBalancer Service IPs ===\"\nCLIENT_GATEWAY_IP=\"\"\nfor service in $LOADBALANCER_SERVICES; do\n  NAMESPACE=$(echo $service | cut -d'/' -f1)\n  SERVICE_NAME=$(echo $service | cut -d'/' -f2)\n  IP=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo \"Pending\")\n  PORT=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[0].port}' 2>/dev/null || echo \"N/A\")\n  echo \"$NAMESPACE/$SERVICE_NAME: $IP:$PORT\"\n  \n  # Extract clientGateway LoadBalancer IP\n  if [ \"$NAMESPACE\" = \"client-gateway\" ] && [ \"$SERVICE_NAME\" = \"client-gateway\" ] && [ \"$IP\" != \"Pending\" ] && [ -n \"$IP\" ]; then\n    CLIENT_GATEWAY_IP=$IP\n    CLIENT_GATEWAY_PORT=$PORT\n    echo \"Found clientGateway LoadBalancer IP: $CLIENT_GATEWAY_IP:$CLIENT_GATEWAY_PORT\"\n  fi\ndone\n\n# Store LoadBalancer IPs in a file for outputs\ncat > /tmp/loadbalancer-ips.json <<EOF\n{\nEOF\n\nFIRST=true\nfor service in $LOADBALANCER_SERVICES; do\n  NAMESPACE=$(echo $service | cut -d'/' -f1)\n  SERVICE_NAME=$(echo $service | cut -d'/' -f2)\n  IP=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo \"Pending\")\n  PORT=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[0].port}' 2>/dev/null || echo \"N/A\")\n  \n  if [ \"$FIRST\" = false ]; then\n    echo \",\" >> /tmp/loadbalancer-ips.json\n  fi\n  FIRST=false\n  \n  SERVICE_KEY=$(echo \"$NAMESPACE-$SERVICE_NAME\" | tr '/' '-' | tr '[:upper:]' '[:lower:]')\n  cat >> /tmp/loadbalancer-ips.json <<EOF\n  \"$SERVICE_KEY\": {\n    \"namespace\": \"$NAMESPACE\",\n    \"service\": \"$SERVICE_NAME\",\n    \"ip\": \"$IP\",\n    \"port\": \"$PORT\"\n  }\nEOF\ndone\n\necho \"}\" >> /tmp/loadbalancer-ips.json\n\ncat /tmp/loadbalancer-ips.json\n\n# Update frontend service with clientGateway external IP if available\nif [ -n \"$CLIENT_GATEWAY_IP\" ] && [ \"$CLIENT_GATEWAY_IP\" != \"Pending\" ]; then\n  echo \"\\n=== Updating frontend service with clientGateway external IP ===\"\n  \n  BACKEND_URL=\"http://$CLIENT_GATEWAY_IP:$CLIENT_GATEWAY_PORT\"\n  BACKEND_AUTH=\"http://$CLIENT_GATEWAY_IP:$CLIENT_GATEWAY_PORT/api/auth\"\n  BACKEND_WSS_URL=\"ws://$CLIENT_GATEWAY_IP:$CLIENT_GATEWAY_PORT/ws\"\n  \n  echo \"Updating frontend env vars:\"\n  echo \"  BACKEND_URL: $BACKEND_URL\"\n  echo \"  BACKEND_AUTH: $BACKEND_AUTH\"\n  echo \"  BACKEND_WSS_URL: $BACKEND_WSS_URL\"\n  \n  # Get current Helm values and update frontend env vars\n  echo \"Retrieving current Helm values...\"\n  helm get values graphpolaris-services -o yaml > /tmp/current-values.yaml 2>/dev/null || echo \"\" > /tmp/current-values.yaml\n  \n  # Use Python to merge values if available, otherwise use kubectl patch\n  if command -v python3 &> /dev/null && python3 -c \"import yaml\" 2>/dev/null; then\n    # Create Python script to update frontend env vars in values\n    export BACKEND_URL_VAL=\"$BACKEND_URL\"\n    export BACKEND_AUTH_VAL=\"$BACKEND_AUTH\"\n    export BACKEND_WSS_URL_VAL=\"$BACKEND_WSS_URL\"\n    export DOCKER_CONFIG_JSON_VAL=\"$DOCKER_CONFIG_JSON\"\n    export ADMIN_USER_VAL=\"$ADMIN_USER\"\n    export ADMIN_PASSWORD_VAL=\"$ADMIN_PASSWORD\"\n    python3 <<PYEOF\nimport yaml\nimport os\n\n# Read current values\nwith open('/tmp/current-values.yaml', 'r') as f:\n    content = f.read()\n    values = yaml.safe_load(content) or {}\n\n# Ensure structure exists\nif 'frontend' not in values:\n    values['frontend'] = {}\nif 'env' not in values['frontend']:\n    values['frontend']['env'] = []\n\n# Update or add the three env vars\nenv_updates = {\n    'BACKEND_URL': os.environ.get('BACKEND_URL_VAL'),\n    'BACKEND_AUTH': os.environ.get('BACKEND_AUTH_VAL'),\n    'BACKEND_WSS_URL': os.environ.get('BACKEND_WSS_URL_VAL')\n}\n\n# Find and update existing env vars\nupdated = set()\nfor env_var in values['frontend']['env']:\n    if env_var.get('name') in env_updates:\n        env_var['value'] = env_updates[env_var['name']]\n        updated.add(env_var['name'])\n\n# Add any missing env vars\nfor name, value in env_updates.items():\n    if name not in updated:\n        values['frontend']['env'].append({'name': name, 'value': value})\n\n# Merge with base values\nbase_values = {\n    'global': {\n        'registryCredentials': {\n            'dockerconfigjson': os.environ.get('DOCKER_CONFIG_JSON_VAL')\n        }\n    },\n    'clientGateway': {\n        'env': {\n            'ADMIN_USER': os.environ.get('ADMIN_USER_VAL'),\n            'ADMIN_PASSWORD': os.environ.get('ADMIN_PASSWORD_VAL')\n        }\n    },\n    'databaseService': {\n        'env': {\n            'ADMIN_USER': os.environ.get('ADMIN_USER_VAL'),\n            'ADMIN_PASSWORD': os.environ.get('ADMIN_PASSWORD_VAL')\n        }\n    }\n}\n\n# Merge base values\nfor key, value in base_values.items():\n    if key not in values:\n        values[key] = value\n    elif isinstance(value, dict):\n        values[key].update(value)\n\n# Write final values\nwith open('/tmp/helm-values-final.yaml', 'w') as f:\n    yaml.dump(values, f, default_flow_style=False, sort_keys=False)\nPYEOF\n    \n    # Upgrade Helm release with merged values\n    echo \"Upgrading Helm release with updated frontend configuration...\"\n    helm upgrade graphpolaris-services \\\n      \"oci://$HELM_REGISTRY/graphpolaris-helm/$HELM_CHART_NAME\" \\\n      --version \"$HELM_CHART_VERSION\" \\\n      -f /tmp/helm-values-final.yaml \\\n      --wait --timeout 15m\n  else\n    # Fallback: Use kubectl to patch the deployment directly\n    echo \"Python/yaml not available, using kubectl to update deployment...\"\n    \n    # Find frontend deployment\n    FRONTEND_DEPLOYMENT=$(kubectl get deployment -n frontend -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo \"\")\n    \n    if [ -n \"$FRONTEND_DEPLOYMENT\" ]; then\n      # Update env vars using kubectl set env\n      kubectl set env deployment/$FRONTEND_DEPLOYMENT -n frontend \\\n        BACKEND_URL=\"$BACKEND_URL\" \\\n        BACKEND_AUTH=\"$BACKEND_AUTH\" \\\n        BACKEND_WSS_URL=\"$BACKEND_WSS_URL\"\n      \n      echo \"Waiting for frontend deployment to restart...\"\n      kubectl rollout status deployment/$FRONTEND_DEPLOYMENT -n frontend --timeout=300s\n    else\n      echo \"WARNING: Could not find frontend deployment to update\"\n    fi\n  fi\n  \n  echo \"Frontend service updated with external clientGateway address: http://$CLIENT_GATEWAY_IP:$CLIENT_GATEWAY_PORT\"\nelse\n  echo \"WARNING: Could not determine clientGateway LoadBalancer IP. Frontend service will use internal addresses.\"\nfi\n"
      }
    },
    {
      "type": "Microsoft.ManagedIdentity/userAssignedIdentities",
      "apiVersion": "2023-01-31",
      "name": "[concat('id-', uniqueString(resourceGroup().id))]",
      "location": "[parameters('location')]"
    },
    {
      "type": "Microsoft.Authorization/roleAssignments",
      "apiVersion": "2022-04-01",
      "name": "[guid(resourceGroup().id, 'aks-deployment-script-rg-contributor')]",
      "dependsOn": [
        "[resourceId('Microsoft.ManagedIdentity/userAssignedIdentities', concat('id-', uniqueString(resourceGroup().id)))]"
      ],
      "properties": {
        "roleDefinitionId": "[subscriptionResourceId('Microsoft.Authorization/roleDefinitions', 'b24988ac-6180-42a0-ab88-20f7382dd24c')]",
        "principalId": "[reference(resourceId('Microsoft.ManagedIdentity/userAssignedIdentities', concat('id-', uniqueString(resourceGroup().id)))).principalId]",
        "principalType": "ServicePrincipal",
        "scope": "[resourceGroup().id]"
      }
    }
  ],
  "outputs": {
    "clusterName": {
      "type": "string",
      "value": "[parameters('clusterName')]"
    },
    "resourceGroup": {
      "type": "string",
      "value": "[resourceGroup().name]"
    },
    "kubeConfigCommand": {
      "type": "string",
      "value": "[concat('az aks get-credentials --resource-group ', resourceGroup().name, ' --name ', parameters('clusterName'))]"
    },
    "loadBalancerIPs": {
      "type": "string",
      "value": "[concat('Check deployment script output or run: kubectl get svc --all-namespaces -o wide | grep LoadBalancer')]"
    },
    "getLoadBalancerIPsCommand": {
      "type": "string",
      "value": "[concat('kubectl get svc --all-namespaces -o wide | grep LoadBalancer')]"
    }
  }
}

