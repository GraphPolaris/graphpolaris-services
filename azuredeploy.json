{
  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "clusterName": {
      "type": "string",
      "defaultValue": "[concat('aks-cluster-', uniqueString(resourceGroup().id))]",
      "metadata": {
        "description": "Name of the AKS cluster"
      }
    },
    "location": {
      "type": "string",
      "defaultValue": "[resourceGroup().location]",
      "metadata": {
        "description": "Location for all resources"
      }
    },
    "nodeCount": {
      "type": "int",
      "defaultValue": 3,
      "minValue": 3,
      "maxValue": 10,
      "metadata": {
        "description": "Number of nodes in the agent pool"
      }
    },
    "nodeVmSize": {
      "type": "string",
      "defaultValue": "Standard_B2s",
      "metadata": {
        "description": "Size of the VMs in the agent pool"
      }
    },
    "kubernetesVersion": {
      "type": "string",
      "defaultValue": "1.31",
      "metadata": {
        "description": "Kubernetes version"
      }
    },
    "dnsPrefix": {
      "type": "string",
      "defaultValue": "[concat('aks-', uniqueString(resourceGroup().id))]",
      "metadata": {
        "description": "DNS prefix for the AKS cluster"
      }
    },
    "servicePrincipalClientId": {
      "type": "string",
      "defaultValue": "",
      "metadata": {
        "description": "Service principal client ID (appId). If not provided, a managed identity will be used."
      }
    },
    "servicePrincipalClientSecret": {
      "type": "securestring",
      "defaultValue": "",
      "metadata": {
        "description": "Service principal client secret. Required if servicePrincipalClientId is provided."
      }
    },
    "helmRegistry": {
      "type": "string",
      "metadata": {
        "description": "Helm OCI registry URL"
      }
    },
    "helmRegistryUser": {
      "type": "string",
      "metadata": {
        "description": "Helm registry username"
      }
    },
    "helmRegistryPassword": {
      "type": "securestring",
      "metadata": {
        "description": "Helm registry password"
      }
    },
    "helmChartName": {
      "type": "string",
      "metadata": {
        "description": "Name of the Helm chart to install"
      }
    },
    "helmChartVersion": {
      "type": "string",
      "metadata": {
        "description": "Version of the Helm chart to install"
      }
    },
    "dockerConfigJson": {
      "type": "securestring",
      "metadata": {
        "description": "Base64 encoded docker config JSON for registry credentials"
      }
    },
    "admin_user": {
      "type": "string",
      "metadata": {
        "description": "Admin user for clientGateway service"
      }
    },
    "admin_password": {
      "type": "securestring",
      "metadata": {
        "description": "Admin password for clientGateway service"
      }
    }
  },
  "variables": {
    "useManagedIdentity": "[empty(parameters('servicePrincipalClientId'))]"
  },
  "resources": [
    {
      "type": "Microsoft.ContainerService/managedClusters",
      "apiVersion": "2023-11-01",
      "name": "[parameters('clusterName')]",
      "location": "[parameters('location')]",
      "identity": "[if(variables('useManagedIdentity'), createObject('type', 'SystemAssigned'), json('null'))]",
      "properties": {
        "kubernetesVersion": "[parameters('kubernetesVersion')]",
        "dnsPrefix": "[parameters('dnsPrefix')]",
        "agentPoolProfiles": [
          {
            "name": "agentpool",
            "count": "[parameters('nodeCount')]",
            "vmSize": "[parameters('nodeVmSize')]",
            "osType": "Linux",
            "mode": "System",
            "type": "VirtualMachineScaleSets",
            "enableAutoScaling": false
          }
        ],
        "servicePrincipalProfile": "[if(variables('useManagedIdentity'), json('null'), createObject('clientId', parameters('servicePrincipalClientId'), 'secret', parameters('servicePrincipalClientSecret')))]",
        "networkProfile": {
          "networkPlugin": "kubenet",
          "loadBalancerSku": "Standard",
          "loadBalancerProfile": {
            "managedOutboundIPs": {
              "count": 1
            }
          }
        },
        "addonProfiles": {
          "httpApplicationRouting": {
            "enabled": false
          }
        },
        "enableRBAC": true
      }
    },
    {
      "type": "Microsoft.Resources/deploymentScripts",
      "apiVersion": "2023-08-01",
      "name": "[concat('deploy-graphpolaris-services-', uniqueString(resourceGroup().id))]",
      "location": "[parameters('location')]",
      "kind": "AzureCLI",
      "dependsOn": [
        "[resourceId('Microsoft.ContainerService/managedClusters', parameters('clusterName'))]"
      ],
      "identity": {
        "type": "UserAssigned",
        "userAssignedIdentities": {
          "[resourceId('Microsoft.ManagedIdentity/userAssignedIdentities', concat('id-', uniqueString(resourceGroup().id)))]": {}
        }
      },
      "properties": {
        "azCliVersion": "2.50.0",
        "timeout": "PT30M",
        "retentionInterval": "P1D",
        "environmentVariables": [
          {
            "name": "CLUSTER_NAME",
            "value": "[parameters('clusterName')]"
          },
          {
            "name": "RESOURCE_GROUP",
            "value": "[resourceGroup().name]"
          },
          {
            "name": "SUBSCRIPTION_ID",
            "value": "[subscription().subscriptionId]"
          },
          {
            "name": "HELM_REGISTRY",
            "value": "[parameters('helmRegistry')]"
          },
          {
            "name": "HELM_REGISTRY_USER",
            "value": "[parameters('helmRegistryUser')]"
          },
          {
            "name": "HELM_REGISTRY_PASSWORD",
            "value": "[parameters('helmRegistryPassword')]"
          },
          {
            "name": "HELM_CHART_NAME",
            "value": "[parameters('helmChartName')]"
          },
          {
            "name": "HELM_CHART_VERSION",
            "value": "[parameters('helmChartVersion')]"
          },
          {
            "name": "DOCKER_CONFIG_JSON",
            "value": "[parameters('dockerConfigJson')]"
          },
          {
            "name": "ADMIN_USER",
            "value": "[parameters('admin_user')]"
          },
          {
            "name": "ADMIN_PASSWORD",
            "value": "[parameters('admin_password')]"
          }
        ],
        "scriptContent": "#!\/bin\/bash\r\nset -e\r\n\r\n# Set the subscription explicitly (managed identity is already authenticated)\r\naz account set --subscription $SUBSCRIPTION_ID\r\n\r\n# Verify subscription\r\naz account show --output table\r\n\r\n# Install kubectl if not available\r\nif ! command -v kubectl &> \/dev\/null; then\r\n  echo \"Installing kubectl...\"\r\n  # Try az aks install-cli first, fallback to direct download\r\n  if ! az aks install-cli 2>\/dev\/null; then\r\n    KUBECTL_VERSION=$(curl -L -s https:\/\/dl.k8s.io\/release\/stable.txt)\r\n    curl -LO \"https:\/\/dl.k8s.io\/release\/${KUBECTL_VERSION}\/bin\/linux\/amd64\/kubectl\"\r\n    chmod +x kubectl\r\n    sudo mv kubectl \/usr\/local\/bin\/kubectl || mv kubectl \/usr\/local\/bin\/kubectl\r\n  fi\r\n  kubectl version --client\r\nfi\r\n\r\n# Install Helm if not available\r\nif ! command -v helm &> \/dev\/null; then\r\n  echo \"Installing Helm...\"\r\n  curl https:\/\/raw.githubusercontent.com\/helm\/helm\/main\/scripts\/get-helm-3 | bash\r\n  helm version\r\nfi\r\n\r\n# Install jq if not available\r\nif ! command -v jq &> \/dev\/null; then\r\n  echo \"Installing jq...\"\r\n  sudo apt-get update && sudo apt-get install -y jq || \\\r\n  (curl -L https:\/\/github.com\/jqlang\/jq\/releases\/download\/jq-1.7.1\/jq-linux-amd64 -o \/tmp\/jq && chmod +x \/tmp\/jq && sudo mv \/tmp\/jq \/usr\/local\/bin\/jq)\r\n  jq --version\r\nfi\r\n\r\n# Get AKS credentials using admin (simpler, doesn't require cluster user role)\r\naz aks get-credentials --resource-group $RESOURCE_GROUP --name $CLUSTER_NAME --admin --overwrite-existing\r\n\r\n# Wait for nodes to be ready\r\nkubectl wait --for=condition=Ready nodes --all --timeout=300s || true\r\n\r\n# Enable OCI support for Helm\r\nexport HELM_EXPERIMENTAL_OCI=1\r\n\r\n# Login to Helm registry\r\necho \"Logging in to Helm registry $HELM_REGISTRY...\"\r\necho \"$HELM_REGISTRY_PASSWORD\" | helm registry login -u \"$HELM_REGISTRY_USER\" --password-stdin \"https:\/\/$HELM_REGISTRY\"\r\n\r\n# Install graphpolaris-services Helm chart\r\necho \"Installing $HELM_CHART_NAME chart version $HELM_CHART_VERSION...\"\r\n\r\n# Create values file with dockerconfigjson and admin credentials for clientGateway and databaseService\r\necho \"Creating Helm values file...\"\r\nif [ -z \"$DOCKER_CONFIG_JSON\" ]; then\r\n  echo \"WARNING: DOCKER_CONFIG_JSON is empty. Image pulls may fail!\"\r\nfi\r\ncat > \/tmp\/helm-values.yaml <<EOF\r\nglobal:\r\n  registryCredentials:\r\n    dockerconfigjson: \"$DOCKER_CONFIG_JSON\"\r\nclientGateway:\r\n  env:\r\n    ADMIN_USER: \"$ADMIN_USER\"\r\n    ADMIN_PASSWORD: \"$ADMIN_PASSWORD\"\r\ndatabaseService:\r\n  env:\r\n    ADMIN_USER: \"$ADMIN_USER\"\r\n    ADMIN_PASSWORD: \"$ADMIN_PASSWORD\"\r\nEOF\r\n\r\necho \"Helm values file created:\"\r\ncat \/tmp\/helm-values.yaml | sed 's\/dockerconfigjson:.*\/dockerconfigjson: [REDACTED]\/' | sed 's\/ADMIN_PASSWORD:.*\/ADMIN_PASSWORD: [REDACTED]\/'\r\n\r\nhelm upgrade --install graphpolaris-services \\\r\n  \"oci:\/\/$HELM_REGISTRY\/graphpolaris-helm\/$HELM_CHART_NAME\" \\\r\n  --version \"$HELM_CHART_VERSION\" \\\r\n  -f \/tmp\/helm-values.yaml \\\r\n  --wait --timeout 15m\r\n\r\n# Wait for all deployments to be ready\r\necho \"Waiting for all deployments to be ready...\"\r\nkubectl wait --for=condition=available --timeout=600s deployment --all --all-namespaces || true\r\n\r\n# Run database migrations for client-gateway service\r\necho \"\\n=== Running database migrations for client-gateway ===\"\r\nCLIENT_GATEWAY_NAMESPACE=\"client-gateway\"\r\nHELM_RELEASE_NAME=\"graphpolaris-services\"\r\n\r\n# Get all LoadBalancer service IPs\r\necho \"\\n=== LoadBalancer Service IPs ===\"\r\nLOADBALANCER_SERVICES=$(kubectl get svc --all-namespaces -o json | jq -r '.items[] | select(.spec.type==\"LoadBalancer\") | \"\\(.metadata.namespace)\/\\(.metadata.name)\"')\r\n\r\nif [ -z \"$LOADBALANCER_SERVICES\" ]; then\r\n  echo \"No LoadBalancer services found yet. Waiting...\"\r\n  sleep 30\r\n  LOADBALANCER_SERVICES=$(kubectl get svc --all-namespaces -o json | jq -r '.items[] | select(.spec.type==\"LoadBalancer\") | \"\\(.metadata.namespace)\/\\(.metadata.name)\"')\r\nfi\r\n\r\n# Wait for LoadBalancer IPs to be assigned\r\nRETRY=0\r\nMAX_RETRIES=30\r\n\r\nwhile [ $RETRY -lt $MAX_RETRIES ]; do\r\n  ALL_IPS_ASSIGNED=true\r\n  \r\n  echo \"\\nChecking LoadBalancer IPs (attempt $((RETRY + 1))\/$MAX_RETRIES)...\"\r\n  \r\n  for service in $LOADBALANCER_SERVICES; do\r\n    NAMESPACE=$(echo $service | cut -d'\/' -f1)\r\n    SERVICE_NAME=$(echo $service | cut -d'\/' -f2)\r\n    IP=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>\/dev\/null || echo \"\")\r\n    \r\n    if [ -z \"$IP\" ]; then\r\n      ALL_IPS_ASSIGNED=false\r\n      echo \"  $NAMESPACE\/$SERVICE_NAME: Pending...\"\r\n    else\r\n      echo \"  $NAMESPACE\/$SERVICE_NAME: $IP\"\r\n    fi\r\n  done\r\n  \r\n  if [ \"$ALL_IPS_ASSIGNED\" = true ] && [ -n \"$LOADBALANCER_SERVICES\" ]; then\r\n    break\r\n  fi\r\n  \r\n  RETRY=$((RETRY + 1))\r\n  if [ $RETRY -lt $MAX_RETRIES ]; then\r\n    sleep 10\r\n  fi\r\n  \r\n  # Refresh service list\r\n  LOADBALANCER_SERVICES=$(kubectl get svc --all-namespaces -o json | jq -r '.items[] | select(.spec.type==\"LoadBalancer\") | \"\\(.metadata.namespace)\/\\(.metadata.name)\"')\r\ndone\r\n\r\n# Output final LoadBalancer IPs\r\necho \"\\n=== Final LoadBalancer Service IPs ===\"\r\nCLIENT_GATEWAY_IP=\"\"\r\nfor service in $LOADBALANCER_SERVICES; do\r\n  NAMESPACE=$(echo $service | cut -d'\/' -f1)\r\n  SERVICE_NAME=$(echo $service | cut -d'\/' -f2)\r\n  IP=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>\/dev\/null || echo \"Pending\")\r\n  PORT=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[0].port}' 2>\/dev\/null || echo \"N\/A\")\r\n  echo \"$NAMESPACE\/$SERVICE_NAME: $IP:$PORT\"\r\n  \r\n  # Extract clientGateway LoadBalancer IP\r\n  if [ \"$NAMESPACE\" = \"client-gateway\" ] && [ \"$SERVICE_NAME\" = \"client-gateway\" ] && [ \"$IP\" != \"Pending\" ] && [ -n \"$IP\" ]; then\r\n    CLIENT_GATEWAY_IP=$IP\r\n    CLIENT_GATEWAY_PORT=$PORT\r\n    echo \"Found clientGateway LoadBalancer IP: $CLIENT_GATEWAY_IP:$CLIENT_GATEWAY_PORT\"\r\n  fi\r\ndone\r\n\r\n# Store LoadBalancer IPs in a file for outputs\r\ncat > \/tmp\/loadbalancer-ips.json <<EOF\r\n{\r\nEOF\r\n\r\nFIRST=true\r\nfor service in $LOADBALANCER_SERVICES; do\r\n  NAMESPACE=$(echo $service | cut -d'\/' -f1)\r\n  SERVICE_NAME=$(echo $service | cut -d'\/' -f2)\r\n  IP=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>\/dev\/null || echo \"Pending\")\r\n  PORT=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[0].port}' 2>\/dev\/null || echo \"N\/A\")\r\n  \r\n  if [ \"$FIRST\" = false ]; then\r\n    echo \",\" >> \/tmp\/loadbalancer-ips.json\r\n  fi\r\n  FIRST=false\r\n  \r\n  SERVICE_KEY=$(echo \"$NAMESPACE-$SERVICE_NAME\" | tr '\/' '-' | tr '[:upper:]' '[:lower:]')\r\n  cat >> \/tmp\/loadbalancer-ips.json <<EOF\r\n  \"$SERVICE_KEY\": {\r\n    \"namespace\": \"$NAMESPACE\",\r\n    \"service\": \"$SERVICE_NAME\",\r\n    \"ip\": \"$IP\",\r\n    \"port\": \"$PORT\"\r\n  }\r\nEOF\r\ndone\r\n\r\necho \"}\" >> \/tmp\/loadbalancer-ips.json\r\n\r\ncat \/tmp\/loadbalancer-ips.json\r\n\r\n# Update frontend service with clientGateway external IP if available\r\nif [ -n \"$CLIENT_GATEWAY_IP\" ] && [ \"$CLIENT_GATEWAY_IP\" != \"Pending\" ]; then\r\n  echo \"\\n=== Updating frontend service with clientGateway external IP ===\"\r\n  \r\n  BACKEND_URL=\"http:\/\/$CLIENT_GATEWAY_IP:$CLIENT_GATEWAY_PORT\"\r\n  BACKEND_AUTH=\"http:\/\/$CLIENT_GATEWAY_IP:$CLIENT_GATEWAY_PORT\/api\/auth\"\r\n  BACKEND_WSS_URL=\"ws:\/\/$CLIENT_GATEWAY_IP:$CLIENT_GATEWAY_PORT\/ws\"\r\n  \r\n  echo \"Updating frontend env vars:\"\r\n  echo \"  BACKEND_URL: $BACKEND_URL\"\r\n  echo \"  BACKEND_AUTH: $BACKEND_AUTH\"\r\n  echo \"  BACKEND_WSS_URL: $BACKEND_WSS_URL\"\r\n  \r\n  # Get current Helm values and update frontend env vars\r\n  echo \"Retrieving current Helm values...\"\r\n  helm get values graphpolaris-services -o yaml > \/tmp\/current-values.yaml 2>\/dev\/null || echo \"\" > \/tmp\/current-values.yaml\r\n  \r\n  # Use Python to merge values if available, otherwise use kubectl patch\r\n  if command -v python3 &> \/dev\/null && python3 -c \"import yaml\" 2>\/dev\/null; then\r\n    # Create Python script to update frontend env vars in values\r\n    export BACKEND_URL_VAL=\"$BACKEND_URL\"\r\n    export BACKEND_AUTH_VAL=\"$BACKEND_AUTH\"\r\n    export BACKEND_WSS_URL_VAL=\"$BACKEND_WSS_URL\"\r\n    export DOCKER_CONFIG_JSON_VAL=\"$DOCKER_CONFIG_JSON\"\r\n    export ADMIN_USER_VAL=\"$ADMIN_USER\"\r\n    export ADMIN_PASSWORD_VAL=\"$ADMIN_PASSWORD\"\r\n    python3 <<PYEOF\r\nimport yaml\r\nimport os\r\n\r\n# Read current values\r\nwith open('\/tmp\/current-values.yaml', 'r') as f:\r\n    content = f.read()\r\n    values = yaml.safe_load(content) or {}\r\n\r\n# Ensure structure exists\r\nif 'frontend' not in values:\r\n    values['frontend'] = {}\r\nif 'env' not in values['frontend']:\r\n    values['frontend']['env'] = []\r\n\r\n# Update or add the three env vars\r\nenv_updates = {\r\n    'BACKEND_URL': os.environ.get('BACKEND_URL_VAL'),\r\n    'BACKEND_AUTH': os.environ.get('BACKEND_AUTH_VAL'),\r\n    'BACKEND_WSS_URL': os.environ.get('BACKEND_WSS_URL_VAL')\r\n}\r\n\r\n# Find and update existing env vars\r\nupdated = set()\r\nfor env_var in values['frontend']['env']:\r\n    if env_var.get('name') in env_updates:\r\n        env_var['value'] = env_updates[env_var['name']]\r\n        updated.add(env_var['name'])\r\n\r\n# Add any missing env vars\r\nfor name, value in env_updates.items():\r\n    if name not in updated:\r\n        values['frontend']['env'].append({'name': name, 'value': value})\r\n\r\n# Merge with base values\r\nbase_values = {\r\n    'global': {\r\n        'registryCredentials': {\r\n            'dockerconfigjson': os.environ.get('DOCKER_CONFIG_JSON_VAL')\r\n        }\r\n    },\r\n    'clientGateway': {\r\n        'env': {\r\n            'ADMIN_USER': os.environ.get('ADMIN_USER_VAL'),\r\n            'ADMIN_PASSWORD': os.environ.get('ADMIN_PASSWORD_VAL')\r\n        }\r\n    },\r\n    'databaseService': {\r\n        'env': {\r\n            'ADMIN_USER': os.environ.get('ADMIN_USER_VAL'),\r\n            'ADMIN_PASSWORD': os.environ.get('ADMIN_PASSWORD_VAL')\r\n        }\r\n    }\r\n}\r\n\r\n# Merge base values\r\nfor key, value in base_values.items():\r\n    if key not in values:\r\n        values[key] = value\r\n    elif isinstance(value, dict):\r\n        values[key].update(value)\r\n\r\n# Write final values\r\nwith open('\/tmp\/helm-values-final.yaml', 'w') as f:\r\n    yaml.dump(values, f, default_flow_style=False, sort_keys=False)\r\nPYEOF\r\n    \r\n    # Upgrade Helm release with merged values\r\n    echo \"Upgrading Helm release with updated frontend configuration...\"\r\n    helm upgrade graphpolaris-services \\\r\n      \"oci:\/\/$HELM_REGISTRY\/graphpolaris-helm\/$HELM_CHART_NAME\" \\\r\n      --version \"$HELM_CHART_VERSION\" \\\r\n      -f \/tmp\/helm-values-final.yaml \\\r\n      --wait --timeout 15m\r\n  else\r\n    # Fallback: Use kubectl to patch the deployment directly\r\n    echo \"Python\/yaml not available, using kubectl to update deployment...\"\r\n    \r\n    # Find frontend deployment\r\n    FRONTEND_DEPLOYMENT=$(kubectl get deployment -n frontend -o jsonpath='{.items[0].metadata.name}' 2>\/dev\/null || echo \"\")\r\n    \r\n    if [ -n \"$FRONTEND_DEPLOYMENT\" ]; then\r\n      # Update env vars using kubectl set env\r\n      kubectl set env deployment\/$FRONTEND_DEPLOYMENT -n frontend \\\r\n        BACKEND_URL=\"$BACKEND_URL\" \\\r\n        BACKEND_AUTH=\"$BACKEND_AUTH\" \\\r\n        BACKEND_WSS_URL=\"$BACKEND_WSS_URL\"\r\n      \r\n      echo \"Waiting for frontend deployment to restart...\"\r\n      kubectl rollout status deployment\/$FRONTEND_DEPLOYMENT -n frontend --timeout=300s\r\n    else\r\n      echo \"WARNING: Could not find frontend deployment to update\"\r\n    fi\r\n  fi\r\n  \r\n  echo \"Frontend service updated with external clientGateway address: http:\/\/$CLIENT_GATEWAY_IP:$CLIENT_GATEWAY_PORT\"\r\nelse\r\n  echo \"WARNING: Could not determine clientGateway LoadBalancer IP. Frontend service will use internal addresses.\"\r\nfi\r\n\r\n# Find client-gateway deployment\r\nif kubectl get namespace $CLIENT_GATEWAY_NAMESPACE &>\/dev\/null; then\r\n  # Try to find deployment with release name prefix first, then fallback to any deployment\r\n  CLIENT_GATEWAY_DEPLOYMENT=$(kubectl get deployment -n $CLIENT_GATEWAY_NAMESPACE -l app.kubernetes.io\/name=client-gateway -o jsonpath='{.items[0].metadata.name}' 2>\/dev\/null || echo \"\")\r\n  \r\n  if [ -n \"$CLIENT_GATEWAY_DEPLOYMENT\" ]; then\r\n    echo \"Found client-gateway deployment: $CLIENT_GATEWAY_DEPLOYMENT\"\r\n    \r\n    # Wait for at least one pod to be ready\r\n    echo \"Waiting for client-gateway pod to be ready...\"\r\n    kubectl wait --for=condition=ready pod -l app.kubernetes.io\/name=client-gateway -n $CLIENT_GATEWAY_NAMESPACE --timeout=300s || true\r\n    \r\n    # Get the first running pod\r\n    CLIENT_GATEWAY_POD=\"\"\r\n    for pod in $(kubectl get pod -n $CLIENT_GATEWAY_NAMESPACE -l app.kubernetes.io\/name=client-gateway -o jsonpath='{.items[*].metadata.name}' 2>\/dev\/null); do\r\n      PHASE=$(kubectl get pod -n $CLIENT_GATEWAY_NAMESPACE $pod -o jsonpath='{.status.phase}' 2>\/dev\/null || echo \"\")\r\n      if [ \"$PHASE\" = \"Running\" ]; then\r\n        CLIENT_GATEWAY_POD=$pod\r\n        break\r\n      fi\r\n    done\r\n    \r\n    # If no running pod found, get the first available pod\r\n    if [ -z \"$CLIENT_GATEWAY_POD\" ]; then\r\n      CLIENT_GATEWAY_POD=$(kubectl get pod -n $CLIENT_GATEWAY_NAMESPACE -l app.kubernetes.io\/name=client-gateway -o jsonpath='{.items[0].metadata.name}' 2>\/dev\/null || echo \"\")\r\n    fi\r\n    \r\n    if [ -n \"$CLIENT_GATEWAY_POD\" ]; then\r\n      echo \"Running migrations in pod: $CLIENT_GATEWAY_POD\"\r\n      \r\n      # Run the migration command\r\n      if kubectl exec -n $CLIENT_GATEWAY_NAMESPACE $CLIENT_GATEWAY_POD -- bun db:migrate; then\r\n        echo \"Database migrations completed successfully\"\r\n      else\r\n        echo \"WARNING: Database migrations failed. This may be expected if migrations were already applied.\"\r\n      fi\r\n    else\r\n      echo \"WARNING: Could not find a ready client-gateway pod to run migrations\"\r\n    fi\r\n  else\r\n    echo \"WARNING: Could not find client-gateway deployment\"\r\n  fi\r\nelse\r\n  echo \"WARNING: client-gateway namespace not found. Skipping migrations.\"\r\nfi\r\n"
      }
    },
    {
      "type": "Microsoft.ManagedIdentity/userAssignedIdentities",
      "apiVersion": "2023-01-31",
      "name": "[concat('id-', uniqueString(resourceGroup().id))]",
      "location": "[parameters('location')]"
    },
    {
      "type": "Microsoft.Authorization/roleAssignments",
      "apiVersion": "2022-04-01",
      "name": "[guid(resourceGroup().id, 'aks-deployment-script-rg-contributor')]",
      "dependsOn": [
        "[resourceId('Microsoft.ManagedIdentity/userAssignedIdentities', concat('id-', uniqueString(resourceGroup().id)))]"
      ],
      "properties": {
        "roleDefinitionId": "[subscriptionResourceId('Microsoft.Authorization/roleDefinitions', 'b24988ac-6180-42a0-ab88-20f7382dd24c')]",
        "principalId": "[reference(resourceId('Microsoft.ManagedIdentity/userAssignedIdentities', concat('id-', uniqueString(resourceGroup().id)))).principalId]",
        "principalType": "ServicePrincipal",
        "scope": "[resourceGroup().id]"
      }
    }
  ],
  "outputs": {
    "clusterName": {
      "type": "string",
      "value": "[parameters('clusterName')]"
    },
    "resourceGroup": {
      "type": "string",
      "value": "[resourceGroup().name]"
    },
    "kubeConfigCommand": {
      "type": "string",
      "value": "[concat('az aks get-credentials --resource-group ', resourceGroup().name, ' --name ', parameters('clusterName'))]"
    },
    "loadBalancerIPs": {
      "type": "string",
      "value": "[concat('Check deployment script output or run: kubectl get svc --all-namespaces -o wide | grep LoadBalancer')]"
    },
    "getLoadBalancerIPsCommand": {
      "type": "string",
      "value": "[concat('kubectl get svc --all-namespaces -o wide | grep LoadBalancer')]"
    }
  }
}

